<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Artificial Neural Networks</title>

		<meta name="description" content="A presentation about Artificial Neural Networks">
		<meta name="author" content="Bohdan Kornienko">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<link rel="stylesheet" href="reveal_js/css/reset.css">
		<link rel="stylesheet" href="reveal_js/css/reveal.css">
		<link rel="stylesheet" href="reveal_js/css/theme/black.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="reveal_js/lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal_js/css/print/pdf.css' : 'reveal_js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
        <style type="text/css">
            .reveal h1 {
                font-size: larger;
            }

            .reveal h2 {
                font-size: smaller;
                text-transform: none;
            }

            div.block {
                border: 1px solid white;
                border-radius: 10px;
                margin: 10px;
                display: inline-block;
                padding: 5px;
                padding-left: 10px;
                padding-right: 10px;
                background-color: rgba(0,0,0, 0.2);

            }
            .reveal blockquote {
                width: 100%;
            }

            .reveal blockquote span.author {
                position: relative;
                display: block;
                font-size: smaller;
                text-align: right;
                margin-top: 5px;
                color: #999;

                i {
                    position: relative;
                    background: #eee;
                    padding-left: 5px;
                    font-style: italic;
                    z-index: 5;
                }
            }

            a.note {
                font-size: 20%;
                display: block;
            }

            div.block {
                border: 1px solid white;
                border-radius: 10px;
                margin: 10px;
                display: inline-block;
                padding: 5px;
                padding-left: 10px;
                padding-right: 10px;
                background-color: rgba(0,0,0, 0.2);
            }

            .emphasize {
                font-weight: bold;
                color: #dbc844;
            }
        </style>
         <style type="text/css">
            table, th, td {
              border: 1px solid white;
            }
        </style>
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
                <section>
                    <h1>Artificial Neural Networks</h1>
                </section>

                <section>
                    <div class="block">CS BA</div>
                    <div class="block">C++</div>
                    <div class="block">Data Science</div>
                    <hr>
                    <div class="block">Drawing</div>
                    <div class="block">Khan Academy</div>
                    <div class="block">Driving</div>
                </section>

                <section>
                    <section>
                        <h1>Non-Linear problems</h1>
                    </section>
                    <section>
                        <img class="stretch" src="images/nonlinear.png">
                    </section>

                    <section>
                        <img style="width:30%" src="images/cats/cute-4646160_960_720.jpg">
                        <img style="width:30%" src="images/cats/cat-cute-cat-animal-pet-preview.jpg">
                        <img style="width:30%" src="images/cats/cute-4912213_960_720.jpg">
                    </section>
                </section>

                <section>
                    <section>
                        <h1>Nature example</h1>
                    </section>
                    <section>
                        <img class="stretch" src="images/neuron_structure.png">
                    </section>
                    <section>
                        <p>Inspired by nature the idea of<br><span class="emphasize">Artificial Neural Networks</span><br>has been developed.</p>
                    </section>
                </section>

                <section>
                    <section>
                        <h1>Neural Network Architecture</h1>
                    </section>

                    <section>
                        <img class="stretch" src="images/ann.png">
                    </section>

                    <section>
                        <h1>Deep Neural Networks</h1>
                        <img class="stretch" src="images/Deep-Neural-Network-architecture.ppm">
                    </section>
                </section>

                <section>
                    <section>
                        <h1>Activation Function</h1>
                    </section>

                    <section>
                        <img class="stretch" src="images/activation_function.png">
                    </section>

                    <section>
                        <img class="stretch" src="images/activations.png">
                    </section>

                    <section>
                        <p>Activation functions introduce <span class="emphasize">non-linearity</span> into the network.</p>
                    </section>

                    <section>
                        <h1>Sigmoid</h1>
                        <script type="math/tex; mode=display">
                            a(x) = g(z) = g(w^Tx) = \frac{1}{1 + e^{-w^Tx}}
                        </script>
                    </section>
                    <section>
                        <ul>
                            <li>Sigmoid outputs values in range [0, 1]</li>
                            <li>0 there is no signal</li>
                            <li>1 there is a strong signal</li>
                        </ul>
                        <p>Which is close model of the biological neuron.</p>
                    </section>
                </section>

                <section>
                    <section>
                        <h1>Neuron weights</h1>
                    </section>

                    <section>
                        <p>Neuron weights defined layer by layer.</p>
                    </section>

                    <section>
                        <img class="stretch" src="images/ann_graph.png">
                        <script type="math/tex; mode=display">
                            W^{(1)} = \begin{bmatrix}
                                       W^{(1)}_{10} & W^{(1)}_{11} & W^{(1)}_{12} \\[0.3em]
                                       W^{(1)}_{20} & W^{(1)}_{21} & W^{(1)}_{22}
                                     \end{bmatrix}
                        </script>
                    </section>
                </section>

                <section>
                    <section>
                        <h1>Forward Propagation</h1>
                    </section>

                    <section>
                        <img class="stretch" src="images/perceptron.png">
                    </section>

                    <section>
                        <img class="stretch" src="images/perceptron.png">
                        <script type="math/tex; mode=display">
                            sigmoid(w, x)= \frac{1}{1 + e^{-w^Tx}}
                        </script>
                    </section>

                    <section>
                        <img class="stretch" src="images/perceptron.png">
                        <script type="math/tex; mode=display">
                            a_{11}(x) = \frac{1}{1 + exp(-(1 \cdot W_{10} +x_1 \cdot W_{11} + x_2 \cdot W_{12})}
                        </script>
                        <script type="math/tex; mode=display">
                            a_{12}(x) = \frac{1}{1 + exp(-(1 \cdot W_{20} +x_1 \cdot W_{21} + x_2 \cdot W_{22})}
                        </script>
                    </section>

                    <section>
                        <script type="math/tex; mode=display">
                            x = \begin{bmatrix}
                                   +1           \\[0.3em]
                                   x_1 \\[0.3em]
                                   x_2
                                 \end{bmatrix},
                            W^{(1)} = \begin{bmatrix}
                                   W^{(1)}_{10} & W^{(1)}_{11} & W^{(1)}_{12} \\[0.3em]
                                   W^{(1)}_{20} & W^{(1)}_{21} & W^{(1)}_{22}
                                 \end{bmatrix}
                        </script>
                        <script type="math/tex; mode=display">
                            a(x) = g(z) = g(W^{(1)}x) = \frac{1}{1 + e^{-W^{(1)}x}}
                        </script>
                    </section>
                </section>

                <section>
                    <section>
                        <h1>Back Propagation</h1>
                    </section>

                    <section>
                         <p> The idea of back propagation was proposed by<br><b>David E. Ruineihart, <span class="emphasize">Geoffrey E. Hinton</span>,<br>and Ronald J. Williams</b>
                        </p>
                        <p>In their paper <span class="emphasize">Learning internal representations by error propagation</span> in 1985</p>
                    </section>

                    <section>
                        <p>BTW</p> <p>The idea of this paper was used in 1989  by <span class="emphasize">LeCun</span> for developing his <span class="emphasize">LeNet</span> architecture.</p>
                    </section>

                    <section>
                        <img class="stretch" src="images/ann_graph.png">
                    </section>

                    <section>
                        <h1>Cost function</h1>
                        <script type="math/tex; mode=display">
                            J(W) = \frac{1}{2} \sum^k_{j=1}(y^{(i)}_j - h_j(x^{(i)}))^2
                        </script>
                    </section>

                    <section>
                        <script type="math/tex; mode=display">
                            f(x) = W^{(1)}x
                        </script>
                        <script type="math/tex; mode=display">
                            g(x) = \frac{1}{1 + e^{-x}}
                        </script>
                        <script type="math/tex; mode=display">
                            h(x) = g(f(x))
                        </script>
                        <script type="math/tex; mode=display">
                            J(x) = (y^{(i)} - h(x^{(i)}))^2 = J(g(f(x)))
                        </script>
                    </section>

                    <section>
                        <script type="math/tex; mode=display">
                            J(x) = (y^{(i)} - h(x^{(i)}))^2 = J(g(f(x)))
                        </script>

                        <script type="math/tex; mode=display">
                            y = J(g(f(x))) \implies \frac{dJ}{dx} = \frac {dJ}{dg} \cdot \frac{dg}{df} \cdot \frac{df}{dx}
                        </script>
                    </section>

                    <section>
                        <h1>Derivative for J</h1>
                        <img class="stretch" src="images/ann_graph.png">
                        <script type="math/tex; mode=display">
                            \frac{\partial J (W)}{\partial a_{2i}} = a_{2i} - y_{i}
                        </script>
                    </section>

                    <section>
                        <h1>Derivative for activation</h1>
                        <img class="stretch" src="images/ann_graph.png">
                        <script type="math/tex; mode=display">
                            \frac{\partial J (W)}{\partial z_{2i}} = \frac{\partial a_{2i}}{\partial z_{2i}} \cdot \frac{\partial J(W)}{\partial a_{2i}}
                                       = a_{2i}(1 - a_{2i}) \cdot (a_{2i} - y_i)
                        </script>
                    </section>

                    <section>
                        <h1>Derivative for dot product</h1>
                        <img class="stretch" src="images/ann_graph.png">
                        <script type="math/tex; mode=display">
                            \frac{\partial J (W)}{\partial W_{ij}} = \frac{\partial z_{2i}}{\partial W_{ij}} \cdot \frac{\partial J(W)}{\partial z_{2i}}
                                           = a_{ij} a_{2i}(1 - a_{2i}) \cdot (a_{2i} - y_i)
                        </script>
                    </section>

                    <section>
                        <h1>Single sample gradient</h1>
                        <script type="math/tex; mode=display">
                            \frac{\partial J (W)}{\partial W_{ij}^{(i)}} = \nabla_W J(W)
                        </script>
                    </section>

                    <section>
                        <h1>Entire dataset gradient</h1>
                        <script type="math/tex; mode=display">
                            \Delta W^{(l)} = \sum^m_{i=1} \left( \nabla_{W^{(l)}} J(W^{(l)}) \right)^{i}
                        </script>
                    </section>
                </section>

                <section>
                    <h1>Weights Update</h1>
                    <script type="math/tex; mode=display">
                        W^{(l)} = W^{(l)} - \alpha \left( \frac{1}{m} \Delta W^{(l)} \right)
                    </script>
                </section>

                <section>
                    <section>
                        <h1>Softmax</h1>

                        <script type="math/tex; mode=display">
                            a_i = \frac{e^{W^T_i x}}{\sum_{j=1}^{k} e^{W^T_i x}}
                        </script>
                    </section>

                    <section>
                        <script type="math/tex; mode=display">
                                x = \begin{bmatrix}
                                   car           \\[0.3em]
                                   cat \\[0.3em]
                                   dog
                                 \end{bmatrix},
                                x = \begin{bmatrix}
                                   0.25           \\[0.3em]
                                   0.6 \\[0.3em]
                                   0.15
                                 \end{bmatrix}
                        </script>
                    </section>
                </section>

                <section>
                    <section>
                        <h1>Architecture types</h1>
                    </section>

                    <section>
                        <h1>Perceptron</h1>
                        <img class="stretch" src="images/perceptron_1.png">
                    </section>

                    <section>
                        <h1>Convolutional Neural Networks</h1>
                        <img class="stretch" src="images/conv_net.jpeg">
                    </section>

                    <section>
                        <h1>Other</h1>
                        <ul>
                            <li>RNN, LSTM, etc</li>
                            <li>GAN</li>
                            <li>Spiking Networks</li>
                            <li>Graph Nets</li>
                        </ul>
                    </section>

                </section>

                <section>
                    <section>
                        <h1>Bias-Variance Tradeoff</h1>
                    </section>
                    <section>
                        <p>If <span class="emphasize">bias</span> is high (underfit): <span class="emphasize">increase</span> number of layers, <span class="emphasize">increase</span> number of parameters</p>
                    </section>
                    <section>
                        <p>If <span class="emphasize">viariance</span> is high (overfit): <span class="emphasize">decrease</span> number of layers, <span class="emphasize">decrease</span> number of parameters</p>
                    </section>

                    <section>
                        <p>Few words on how to construct your own architecture.</p>
                        <img class="stretch" src="images/debug-losses.png">
                    </section>

                </section>

                <section>
                    <section>
                        <h1>Such as life</h1>
                    </section>
                    <section>
                        <h1>tensorflow vs pytorch</h1>

                        <p><span class="emphasize">Tensorflow</span> is good for deployment.</p>
                        <p><span class="emphasize">PyTorch</span> for prototyping.</p>

                        <p>In general, it is not about tool it is about the problem.</p>
                    </section>

                    <section>
                        <h1>Log the progress</h1>
                        <ul>
                            <li>Tensorboard</li>
                            <li>Visdom</li>
                            <li>Console output + log files</li>
                        </ul>
                    </section>

                    <section>
                        <h1>Train loop vs Callbacks</h1>
                    </section>

                    <section>
                        <h1>Callbacks</h1>

                        <table>
                            <tr>
                                <th>Pros</th>
                                <th>Cons</th>
                            </tr>
                            <tr>
                                <td>
                                    <ul>
                                        <li>Compact code</li>
                                        <li>Things handled behind the scene</li>
                                        <li>Less work</li>
                                    </ul>
                                </td>
                                <td>
                                    <ul>
                                        <li>Framework related</li>
                                        <li>No control over the train loop</li>
                                        <li>Sometimes difficult to debug</li>
                                    </ul>
                                </td>
                            </tr>
                        </table>
                    </section>
                    <section>
                        <h1>Manual train loop</h1>

                        <table>
                            <tr>
                                <th>Pros</th>
                                <th>Cons</th>
                            </tr>
                            <tr>
                                <td>
                                    <ul>
                                        <li>Full control of the process</li>
                                        <li>Framework agnostic</li>
                                        <li>Easy to debug</li>
                                    </ul>
                                </td>
                                <td>
                                    <ul>
                                        <li>Time consuming</li>
                                    </ul>
                                </td>
                            </tr>
                        </table>
                    </section>

                </section>

                <section>
                    <h1>References</h1>
                    <ul>
                        <li><a href="https://apps.dtic.mil/dtic/tr/fulltext/u2/a164453.pdf">Hinton, et. al. Learning internal representations by error propagation</a></li>
                        <li><a href="https://www.deeplearningbook.org/">Deep Learning Book</a></li>
                        <li><a href="http://cs231n.stanford.edu/2016/syllabus">cs321n</a></li>
                        <li><a href="https://www.youtube.com/playlist?list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg">cs231n videos</a></li>
                        <li><a href="https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f">Medium: Optimization Algorithms</a></li>
                        <li><a href="https://github.com/facebookresearch/visdom">Facebook Visdom</a></li>
                        <li><a href="https://github.com/deepmind/graph_nets">Graph Nets</a></li>
                    </ul>
                </section>

                <section>
                    <h1>Cheers!</h1>
                </section>

                <section>
                    <img class="stretch" src="images/qr_link.png">
                </section>

                <!--
                    Things to add to the presentation:
                        - Gradient exposion
                        - Vanishing gradient problem
                        - batch norm
                        - practical advice on how to show loss functions, the code structure etc.
                        - 2d convolution as a dot product
                        - optimizers: https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f
                        - Expand info on different architecture types
                        - Feature network + Task network thing
                -->

			</div>

		</div>

		<script src="reveal_js/js/reveal.js"></script>

		<script>

			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				center: true,
				hash: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'reveal_js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'reveal_js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'reveal_js/plugin/highlight/highlight.js', async: true },
					{ src: 'reveal_js/plugin/search/search.js', async: true },
					{ src: 'reveal_js/plugin/zoom-js/zoom.js', async: true },
					{ src: 'reveal_js/plugin/notes/notes.js', async: true },
                    { src: 'reveal_js/plugin/math/math.js', async: true }
				]
			});

		</script>
	</body>
</html>
